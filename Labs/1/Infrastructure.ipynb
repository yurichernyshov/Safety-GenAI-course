{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fbafc9c-349c-4f61-943c-a9300374f9e2",
   "metadata": {},
   "source": [
    "# Lab 1-1 \"Infrastructure\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7badd01-c6c4-4db9-b727-f2854eb16286",
   "metadata": {},
   "source": [
    "## Lab 1-1 description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536eed34-e8cb-4d05-bb3c-76e902893093",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f387d3ae-9954-4597-84e6-34323ce7fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No LSB modules are available.\n",
      "Distributor ID:\tUbuntu\n",
      "Description:\tUbuntu 24.04.4 LTS\n",
      "Release:\t24.04\n",
      "Codename:\tnoble\n"
     ]
    }
   ],
   "source": [
    "!lsb_release -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2900bec-c4a3-409e-9bc8-ce28e62777a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8db096-10d6-4b97-ac61-7bc2494d1b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain==1.2.10\n",
      "langchain-chroma==1.1.0\n",
      "langchain-classic==1.0.1\n",
      "langchain-community==0.4.1\n",
      "langchain-core==1.2.15\n",
      "langchain-huggingface==1.2.0\n",
      "langchain-ollama==1.0.1\n",
      "langchain-text-splitters==1.1.1\n",
      "sentence-transformers==5.2.2\n",
      "transformers==4.57.6\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep -E \"langchain|transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535c73ad-0a6f-4c7d-b687-311f03f25206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nollama version is 0.17.0\n"
     ]
    }
   ],
   "source": [
    "!ollama --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887d9a44-120a-4fe0-bad5-e28caae77f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6nNAME             ID              SIZE      MODIFIED       \n",
      "qwen3:4b         359d7dd4bcda    2.5 GB    24 minutes ago    \n",
      "llama3:latest    365c0bd3c000    4.7 GB    31 minutes ago    \n",
      "phi3:latest      4f2222927938    2.2 GB    21 hours ago      \n",
      "qwen:0.5b        b5dc5e784f2a    394 MB    22 hours ago      \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b1632-e3f1-4acf-bd30-0ce16053b742",
   "metadata": {},
   "source": [
    "# Task 1: simple LLM response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40e129b-f742-47c7-8712-6a4e6d3b8200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ychernyshov/urfu/1/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      " Langchain is a programming language that was created by Google. Langchain's syntax is similar to other modern programming languages, such as Python and Java.\n",
      "\n",
      "One of the key features of Langchain is its ability to execute arbitrary code. This allows developers to write modular, reusable code that can be easily integrated into other applications or systems.\n",
      "\n",
      "Another key feature of Langchain is its ability to handle exceptions in execution. This allows developers to design robust and error-free programs that are resistant to unexpected errors.\n",
      "\n",
      "Overall, Langchain's syntax, ability to execute arbitrary code, and handling exceptions make it an attractive choice for developers looking to write modular, reusable code that can be easily integrated into other applications or systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM  \n",
    "\n",
    "llm = OllamaLLM(model=\"qwen:0.5b\", temperature=0.7)\n",
    "response = llm.invoke(\"what is langchain?\")\n",
    "print(\"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341b6337-df68-442c-8c33-7e9c2217f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n",
      " **LangChain** is an **open-source framework** designed to help developers build **applications powered by large language models (LLMs)**. It simplifies the process of integrating LLMs (like OpenAI's GPT, Anthropic's Claude, or Meta's Llama) into real-world applications by providing tools for:\n",
      "\n",
      "1. **Connecting LLMs to data** (e.g., databases, APIs, files)\n",
      "2. **Creating chains of reasoning** (e.g., step-by-step workflows)\n",
      "3. **Handling context** (e.g., remembering past interactions)\n",
      "4. **Building agents** (e.g., chatbots that can search the web or execute tasks)\n",
      "5. **Evaluating and improving** LLM outputs\n",
      "\n",
      "### Why is LangChain important?\n",
      "- **Solves a real problem**: Building apps with LLMs is complex (e.g., managing context, handling errors, connecting to external data). LangChain abstracts these challenges.\n",
      "- **Modular & flexible**: Developers can plug in different tools (e.g., vector databases, APIs) without rewriting everything.\n",
      "- **Community-driven**: It‚Äôs widely used by developers to build practical AI apps (e.g., chatbots, document summarizers, code assistants).\n",
      "\n",
      "### Simple Example\n",
      "Imagine building a **chatbot that answers questions about a company‚Äôs documents**:\n",
      "1. Use LangChain to connect the chatbot to your company‚Äôs PDF files.\n",
      "2. Let the LLM search the documents for relevant info.\n",
      "3. Return a clear, concise answer to the user.\n",
      "\n",
      "**Without LangChain**: You‚Äôd have to manually handle file parsing, context management, and error handling ‚Üí *very time-consuming*.\n",
      "**With LangChain**: You write a few lines of code ‚Üí *quickly build a functional app*.\n",
      "\n",
      "---\n",
      "\n",
      "### ‚ö†Ô∏è Common Confusion\n",
      "- **LangChain ‚â† the company**: There‚Äôs also a company called **LangChain** (founded by the same people who created the framework), but **the framework itself is open-source** (GitHub: [langchain-ai/langchain](https://github.com/langchain-ai/langchain)).\n",
      "- **Not an LLM itself**: LangChain is a *toolkit* for using LLMs ‚Äî it doesn‚Äôt create the models (that‚Äôs handled by providers like OpenAI).\n",
      "\n",
      "### In a Nutshell\n",
      "> **LangChain = The \"glue\" that lets developers build practical AI apps using LLMs without deep expertise in AI infrastructure.**\n",
      "\n",
      "If you‚Äôre a developer, it‚Äôs your go-to for building LLM-powered apps. If you‚Äôre a non-technical person, think of it as **\"the toolkit for making AI chatbots and assistants work smoothly.\"**\n",
      "\n",
      "*Want a quick demo? Try [LangChain‚Äôs official tutorial](https://python.langchain.com/docs/get_started)* üòä\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=\"qwen3:4b\", temperature=0)\n",
    "response = llm.invoke(\"what is langchain?\")\n",
    "print(\"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2fac21-2912-425f-aa36-50ff44a2e8d5",
   "metadata": {},
   "source": [
    "# Task 2: prompt chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e552753c-bc7d-4aca-a6bf-39ebdb0a6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db6090b4-3dcf-419e-9940-ffe61ed83227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'JailBrake' –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. \n",
      "\n",
      "–í–æ—Ç –ø—Ä–∏–º–µ—Ä –∫–æ–¥–∞:\n",
      "\n",
      "```\n",
      "public class MyClass {\n",
      "    public static void main(String[] args) {\n",
      "        System.out.println(\"Hello World\");\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "–í —ç—Ç–æ–º –ø—Ä–∏–º–µ—Ä–µ –∫–æ–¥–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –∫–æ–¥ –º—ã—à–µ—á–Ω–æ–≥–æ –∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á. 8.79245924949646\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ {—Ç–µ–º–∞}. –û–±—ä—è—Å–Ω–∏ –ø–æ–Ω—è—Ç–∏–µ '{–ø–æ–Ω—è—Ç–∏–µ}' –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ.\"\n",
    ")\n",
    "llm = OllamaLLM(model=\"qwen:0.5b\")\n",
    "chain = prompt | llm  # —Å–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∞—è —Ü–µ–ø–æ—á–∫–∞ (LangChain 0.2+)\n",
    "\n",
    "start = time.time()\n",
    "result = chain.invoke({\"—Ç–µ–º–∞\": \"LLM security\", \"–ø–æ–Ω—è—Ç–∏–µ\": \"jailbrake\"})\n",
    "print(result, time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bc07152-3f01-4f77-8abe-aacd90f6a34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Jailbreak** ‚Äî —ç—Ç–æ —Ç–µ—Ö–Ω–∏–∫–∞, –∫–æ—Ç–æ—Ä—É—é –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–ª—è –æ–±—Ö–æ–¥–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ LLM (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–∞–≤–∏–ª, –∑–∞–ø—Ä–µ—â–∞—é—â–∏—Ö –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—é –∏–ª–∏ —É—Ç–µ—á–∫—É –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏) –∏ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –∏–ª–∏ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç. –ü—Ä–∏–º–µ—Ä: –∑–∞—Å—Ç–∞–≤–∏—Ç—å –º–æ–¥–µ–ª—å –æ–±—Å—É–∂–¥–∞—Ç—å –≤–æ–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è, –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ –≤ –µ—ë –æ–±—É—á–µ–Ω–∏–∏. 1219.086008310318\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ {—Ç–µ–º–∞}. –û–±—ä—è—Å–Ω–∏ –ø–æ–Ω—è—Ç–∏–µ '{–ø–æ–Ω—è—Ç–∏–µ}' –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ.\"\n",
    ")\n",
    "llm = OllamaLLM(model=\"qwen3:4b\")\n",
    "chain = prompt | llm  \n",
    "\n",
    "start = time.time()\n",
    "result = chain.invoke({\"—Ç–µ–º–∞\": \"LLM security\", \"–ø–æ–Ω—è—Ç–∏–µ\": \"jailbrake\"})\n",
    "print(result, time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8c2fc-e375-46bc-9493-222f6a629312",
   "metadata": {},
   "source": [
    "# Task 3: RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ed2047-edfd-4fbe-ad65-1ee14a11584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_classic.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3db2381-595e-4515-a9a1-5dc32f3a8235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û—Ç–≤–µ—Ç: The main text is from Lewis Carroll's poem \"Jabberwocky,\" which appears in his novel \"Through the Looking-Glass, and What Alice Found There.\" The excerpt provided includes nonsensical words used throughout the entirety of this famous work.\n",
      "–ò—Å—Ç–æ—á–Ω–∏–∫: And, as in uffish thought he stood,\n",
      "The Jabberwock, with eyes of flame,\n",
      "Came whiffling through the t...\n"
     ]
    }
   ],
   "source": [
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª data.txt —Å —Ç–µ–∫—Å—Ç–æ–º)\n",
    "loader = TextLoader(\"data.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "# 3. –í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "# 4. –¶–µ–ø–æ—á–∫–∞ QA\n",
    "llm = OllamaLLM(model=\"phi3\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 5. –ó–∞–ø—Ä–æ—Å\n",
    "query = \"–û —á—ë–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç?\"\n",
    "result = qa_chain.invoke(query)\n",
    "print(\"–û—Ç–≤–µ—Ç:\", result[\"result\"])\n",
    "print(\"–ò—Å—Ç–æ—á–Ω–∏–∫:\", result[\"source_documents\"][0].page_content[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b30b02-188e-4206-9102-9d9e1527b60a",
   "metadata": {},
   "source": [
    "# Task 4: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84840a9b-4cd4-4039-82fd-ef6b265f41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import AgentExecutor, create_react_agent, create_tool_calling_agent\n",
    "from langchain_core.tools import Tool, tool\n",
    "from langchain_ollama import OllamaLLM, ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3baea00-6f07-4fb1-a7f1-69db38a98db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ.\n",
    "    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: +, -, *, /, **, —Å–∫–æ–±–∫–∏.\n",
    "    –ü—Ä–∏–º–µ—Ä: \"2 + 2 * 3\", \"(10 - 5) * 4\", \"2 ** 10\"\n",
    "    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ª—é–±—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—á—ë—Ç–æ–≤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # –û—á–∏—â–∞–µ–º –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç –æ–ø–∞—Å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å!)\n",
    "        allowed_chars = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"–û—à–∏–±–∫–∞: –ù–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –≤—ã—Ä–∞–∂–µ–Ω–∏–∏\"\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        result = eval(expression)\n",
    "        return f\"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}\"\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        return \"–û—à–∏–±–∫–∞: –î–µ–ª–µ–Ω–∏–µ –Ω–∞ –Ω–æ–ª—å\"\n",
    "    except SyntaxError:\n",
    "        return \"–û—à–∏–±–∫–∞: –ù–µ–≤–µ—Ä–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –≤—ã—Ä–∞–∂–µ–Ω–∏—è\"\n",
    "    except Exception as e:\n",
    "        return f\"–û—à–∏–±–∫–∞: {str(e)}\"\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤\n",
    "tools = [calculate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e500f41-3971-407f-b79a-6d7b6be43738",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3:4b\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6055cf6e-b90b-4ea8-8a0b-fdaba7276f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä—É.\n",
    "    \n",
    "–ü–†–ê–í–ò–õ–ê:\n",
    "1. –î–ª—è –ª—é–±—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç 'calculate'\n",
    "2. –ù–µ –ø—ã—Ç–∞–π—Å—è –≤—ã—á–∏—Å–ª—è—Ç—å –≤ —É–º–µ —Å–ª–æ–∂–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è\n",
    "3. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å —Å —á–∏—Å–ª–∞–º–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä\n",
    "4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\"\"\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d87469-c108-4009-bc92-68749b8c7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,           # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ö–æ–¥ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π\n",
    "    max_iterations=5,       # –ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫\n",
    "    handle_parsing_errors=True,  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –æ—à–∏–±–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48a83a91-b30b-47a1-b0e0-ae38c08ca392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "–í—ã:  2+2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `calculate` with `{'expression': '2 + 2'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m–†–µ–∑—É–ª—å—Ç–∞—Ç: 4\u001b[0m\u001b[32;1m\u001b[1;3m–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è: 4\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "–ê–≥–µ–Ω—Ç: –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è: 4\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "–í—ã:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "        try:\n",
    "            user_input = input(\"\\n–í—ã: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"–≤—ã—Ö–æ–¥\"]:\n",
    "                print(\"–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
    "                break\n",
    "            \n",
    "            response = agent_executor.invoke({\"input\": user_input})\n",
    "            print(f\"–ê–≥–µ–Ω—Ç: {response['output']}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n–î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa542b-1675-4760-84d4-0d9052efeb55",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2eb5b-70ac-4444-aca0-fe3a7f975e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
